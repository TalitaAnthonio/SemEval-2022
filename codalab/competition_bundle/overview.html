<h3>SemEval-2022 Task 7: Identifying Plausible Clarifications of Implicit and Underspecified Phrases in Instructional Texts</h3>
<div>
    <p>
        The goal of this shared task is to evaluate the ability of NLP systems to distinguish between <b>plausible and implausible clarifications</b> of an instruction.
    </p>
    <p>
        A clarification is a revision that makes a text easier to understand and avoids possible misunderstandings.
        For example, a clarification can make implicit elements in a text explicit, resolve ambiguities or replace underspecified phrases by a more precise expression.
        These modifications are particularly important in instructional texts like how-to guides, manuals or recipes to ensure that they describe clearly enough what steps must be followed to achieve a specific goal.
    </p>
    <p>
        Therefore, the task of determining how plausible a clarification is in a given context can be useful to
        <ul>
            <li>find ways to improve instructional texts</li>
            <li>evaluate to what extent current NLP systems are able to handle implicit, ambiguous and underspecified language</li>
            <li>go beyond the surface form of a text and take multiple plausible interpretations into account</li>
        </ul>
    </p>
</div>

<h4>Task Set-Up</h4>
<div>
    <ul> 
        <li>The data contains instructional texts with clarifications. </li>
        <li>A clarification is a word/phrase that was inserted to specify information in the instruction ("filler"). </li>
        <li>Systems have to predict the plausibility of such a clarification in a given context.</li>
        <li>The plausibility can be predicted in two tasks: a classification task (Subtask A) and ranking task (Subtask B). </li>
    </ul>
</div>

<h5>Subtask A: Multi-Class Classification</h5>
<div>
    <p>The goal is to predict a class label (IMPLAUSIBLE, NEUTRAL, PLAUSIBLE) given the clarification and its context.</p>
    <p>Submitted systems will be evaluated based on the accuracy score.</p>
</div>

<h5>Subtask B: Ranking</h5>
<div>
    <p>The goal is to predict the plausibility score on a scale from 1 to 5 given the clarification and its context.</p>
    <p>Submitted systems will be evaluated based on <a href="http://sites.utexas.edu/sos/guided/inferential/numeric/bivariate/rankcor/">Spearman's rank correlation coefficient</a>
        (correlation between gold and predicted plausibility scores, according to their overall ranks).</p>
</div>

<h4>Want to Get in Touch? Need a Clarification?</h4>
<div>
    <p>There is no formal registration for the task yet. Anyone interested can join our Google group <a href="https://groups.google.com/g/semeval2022-task7/">here</a>.</p>
    <p>For further information and to access the trial and training data, visit <a href="https://clarificationtask.github.io">the task website</a>.</p>
</div>